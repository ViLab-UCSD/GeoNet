seed: 1
model:
    feature_extractor:
        arch: resnet50
        pretrained: True
    classifier:
        arch: hdacls
        nonlinear: relu
        feat_size: [2048, 256]
        n_class: 31 
        toalign: true
        hda: true
    discriminator:
        arch: advnet
        in_feature: 256 # bottleneck_dim x n_class (if not using random layer)
        hidden_size: 1024
data:
    source:
        loader: FileDataLoader
        data_root: /data/
        train: source.txt
        val: source.txt
        n_workers: 4
        drop_last: true
        n_class: 31 # domainnet
        sampler:
            name: random
            #name: class_balanced
        imbalance_factor: 1
        reversed: false
        mode: exp
        inverse: false
    target:
        loader: FileDataLoader
        data_root: /data/
        train: target.txt
        val: target.txt
        n_workers: 4
        drop_last: true
        n_class: 31 # domainnet
        sampler:
            name: random
        imbalance_factor: 1
        reversed: false
        mode: exp
        inverse: false
training:
    trainer: toalign
    losses:
        loss_cls:
            name: cross_entropy
        loss_align:
            name: dann
            use_entropy: true
            coeff: 1 # CDAN loss coeff
        loss_toalign:
            name: HDALoss
            coeff: 1
    iteration: 100004
    batch_size: 32
    # batch_size: 256
    val_interval: 5000
    save_interval: 5000
    print_interval: 2500
    optimizer:
        name: sgd
        # lr: 0.0004
        # lr: 0.03
        momentum: 0.9
        weight_decay: 0.0005
        nesterov: true
    scheduler:
        init_lr: 0.001
        name: inv
        gamma: 0.001
        power: 0.75
    # scheduler:
    #     name: multiStepLr
    #     gamma: 0.1
    #     milestones: [35000,50000,60000]
    resume:
        #model: runs/plain/clipart/ep-200_model.pkl
        model: 
        load_cls: false
        param_only: true
exp: a2d_noldam
